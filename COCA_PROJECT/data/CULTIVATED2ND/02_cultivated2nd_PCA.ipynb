{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74c7fa7-5a3f-4e1d-ab01-495b673c2346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Formatting for 00_cultivated2nd_raw_landmarks.csv ---\n",
      "Successfully loaded 00_cultivated2nd_raw_landmarks.csv. First 5 rows:\n",
      "          file            species  px_cm  base_x  base_y   tip_x   tip_y\n",
      "0  AMA1A_a.tif  Erythroxylym coca   28.4  271.00  195.25  127.50  189.00\n",
      "1  AMA1A_b.tif  Erythroxylym coca   28.4  275.00  202.75  125.00  193.25\n",
      "2  AMA1A_c.tif  Erythroxylym coca   28.4  271.25  202.50  127.75  194.00\n",
      "3  AMA1A_d.tif  Erythroxylym coca   28.4  281.00  208.00  118.00  193.00\n",
      "4  AMA1A_e.tif  Erythroxylym coca   28.4  284.25  210.25  115.50  200.00\n",
      "\n",
      "'full_name' column created based on variety mapping.\n",
      "\n",
      "'type' column created based on substring search in 'species'.\n",
      "\n",
      "Formatted data saved to 01_cultivated2nd_landmarks.csv.\n",
      "First 5 rows of the formatted data:\n",
      "          file            species  px_cm  base_x  base_y   tip_x   tip_y  \\\n",
      "0  AMA1A_a.tif  Erythroxylym coca   28.4  271.00  195.25  127.50  189.00   \n",
      "1  AMA1A_b.tif  Erythroxylym coca   28.4  275.00  202.75  125.00  193.25   \n",
      "2  AMA1A_c.tif  Erythroxylym coca   28.4  271.25  202.50  127.75  194.00   \n",
      "3  AMA1A_d.tif  Erythroxylym coca   28.4  281.00  208.00  118.00  193.00   \n",
      "4  AMA1A_e.tif  Erythroxylym coca   28.4  284.25  210.25  115.50  200.00   \n",
      "\n",
      "  variety plant leaf full_name  type  \n",
      "0     AMA    1A    a   amazona  coca  \n",
      "1     AMA    1A    b   amazona  coca  \n",
      "2     AMA    1A    c   amazona  coca  \n",
      "3     AMA    1A    d   amazona  coca  \n",
      "4     AMA    1A    e   amazona  coca  \n",
      "\n",
      "--- 'species' Column Breakdown ---\n",
      "species\n",
      "Erythroxylym coca              2763\n",
      "Erythroxylym novogranatense     490\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- 'full_name' Column Breakdown ---\n",
      "full_name\n",
      "chiparra                  342\n",
      "DES                       229\n",
      "tingo pajarita caucana    200\n",
      "crespa                    186\n",
      "peruana roja              165\n",
      "POM                       164\n",
      "patirroja                 164\n",
      "chirosa                   162\n",
      "boliviana blanca          161\n",
      "boliviana roja            160\n",
      "tingo maria               158\n",
      "dulce                     157\n",
      "gigante                   156\n",
      "trujillense caucana       156\n",
      "BON                       155\n",
      "tingo peruana             154\n",
      "guayaba roja              152\n",
      "amazona                   128\n",
      "tingo pajarita            104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Data Formatting Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_METADATA_FILE = \"00_cultivated2nd_raw_landmarks.csv\"\n",
    "OUTPUT_METADATA_FILE = \"01_cultivated2nd_landmarks.csv\" # This will be the output file\n",
    "\n",
    "# Dictionary for mapping 'variety' codes to 'full_name'\n",
    "VARIETY_FULL_NAMES = {\n",
    "    \"BRO\": \"boliviana roja\",\n",
    "    \"CHA\": \"chiparra\",\n",
    "    \"CHI\": \"chirosa\",\n",
    "    \"DUL\": \"dulce\",\n",
    "    \"GUR\": \"guayaba roja\",\n",
    "    \"PAT\": \"patirroja\",\n",
    "    \"PER\": \"peruana roja\",\n",
    "    \"TMA\": \"tingo maria\",\n",
    "    \"TPE\": \"tingo peruana\",\n",
    "    \"AMA\": \"amazona\",\n",
    "    \"BOB\": \"boliviana blanca\",\n",
    "    \"GIG\": \"gigante\",\n",
    "    \"TRU\": \"trujillense caucana\",\n",
    "    \"TIP\": \"tingo pajarita\",\n",
    "    \"TPC\": \"tingo pajarita caucana\",\n",
    "    \"CRE\": \"crespa\"\n",
    "}\n",
    "\n",
    "print(f\"--- Starting Data Formatting for {RAW_METADATA_FILE} ---\")\n",
    "\n",
    "# --- Load the raw metadata ---\n",
    "try:\n",
    "    df = pd.read_csv(RAW_METADATA_FILE)\n",
    "    print(f\"Successfully loaded {RAW_METADATA_FILE}. First 5 rows:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {RAW_METADATA_FILE} not found. Please ensure it's in the same directory as this notebook.\")\n",
    "    exit()\n",
    "\n",
    "# --- Extract 'variety', 'plant', and 'leaf' from 'file' column ---\n",
    "def parse_filename(filename):\n",
    "    match = re.match(r'^([A-Z]{3})([^_]+)_([^_.]+)\\.tif$', filename)\n",
    "    if match:\n",
    "        variety = match.group(1)\n",
    "        plant = match.group(2)\n",
    "        leaf = match.group(3)\n",
    "        return variety, plant, leaf\n",
    "    else:\n",
    "        print(f\"Warning: Filename '{filename}' does not match expected pattern. Returning NaN for extracted columns.\")\n",
    "        return pd.NA, pd.NA, pd.NA\n",
    "\n",
    "df[['variety', 'plant', 'leaf']] = df['file'].apply(lambda x: pd.Series(parse_filename(x)))\n",
    "\n",
    "# --- Create 'full_name' column based on 'variety' mapping ---\n",
    "df['full_name'] = df['variety'].map(VARIETY_FULL_NAMES).fillna(df['variety'])\n",
    "print(\"\\n'full_name' column created based on variety mapping.\")\n",
    "\n",
    "# --- Create 'type' column based on substring search in 'species' ---\n",
    "# Using apply with a lambda function that checks for substrings\n",
    "def get_type_from_species(species_name):\n",
    "    if \"coca\" in str(species_name).lower():\n",
    "        return \"coca\"\n",
    "    elif \"novogranatense\" in str(species_name).lower():\n",
    "        return \"novogranatense\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "df['type'] = df['species'].apply(get_type_from_species)\n",
    "print(\"\\n'type' column created based on substring search in 'species'.\")\n",
    "\n",
    "\n",
    "# --- Save the formatted DataFrame to a new CSV ---\n",
    "df.to_csv(OUTPUT_METADATA_FILE, index=False)\n",
    "print(f\"\\nFormatted data saved to {OUTPUT_METADATA_FILE}.\")\n",
    "print(\"First 5 rows of the formatted data:\")\n",
    "print(df.head())\n",
    "\n",
    "# --- Print unique values and counts for 'species' ---\n",
    "print(\"\\n--- 'species' Column Breakdown ---\")\n",
    "species_counts = df['species'].value_counts()\n",
    "print(species_counts)\n",
    "\n",
    "# --- Print unique values and counts for 'full_name' ---\n",
    "print(\"\\n--- 'full_name' Column Breakdown ---\")\n",
    "full_name_counts = df['full_name'].value_counts()\n",
    "print(full_name_counts)\n",
    "\n",
    "print(\"\\n--- Data Formatting Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472ad55e-ee45-44b7-a103-f402505ac1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Starting Analysis for CULTIVATED1ST Dataset ==========\n",
      "Saving outputs to directory: ./03_morphometrics_output_cultivated1st_combined/\n",
      "Metadata loaded from: ../CULTIVATED1ST/01_cultivated1st_landmarks.csv\n",
      "First 5 rows of loaded metadata:\n",
      "         file variety       full_name  type  plant leaf  px_cm  base_x  \\\n",
      "0  BRO4_e.tif     BRO  boliviana roja  coca      4    e  28.42    95.5   \n",
      "1  BRO4_d.tif     BRO  boliviana roja  coca      4    d  28.42    85.0   \n",
      "2  BRO4_c.tif     BRO  boliviana roja  coca      4    c  28.42    78.0   \n",
      "3  BRO4_b.tif     BRO  boliviana roja  coca      4    b  28.42   104.0   \n",
      "4  BRO4_a.tif     BRO  boliviana roja  coca      4    a  28.42    75.0   \n",
      "\n",
      "   base_y  tip_x  tip_y  \n",
      "0   194.5  302.5  197.5  \n",
      "1   199.5  315.0  201.5  \n",
      "2   202.5  321.0  204.0  \n",
      "3   192.0  296.5  201.0  \n",
      "4   187.5  325.5  202.5  \n",
      "Found 319 image files to process from metadata.\n",
      "\n",
      "--- Preprocessing Images and Interpolating Pseudo-Landmarks ---\n",
      "--- Calculating GPA Mean ---\n",
      "--- Aligning Leaves to GPA Mean ---\n",
      "--- Visualizing GPA Aligned Shapes ---\n",
      "GPA mean shape plot saved to ./03_morphometrics_output_cultivated1st_combined/gpa_mean_shape_cultivated1st.png\n",
      "\n",
      "--- Performing Full PCA and Generating Explained Variance Report ---\n",
      "PC1: 65.16%, 65.16%\n",
      "PC2: 16.16%, 81.32%\n",
      "PC3: 7.69%, 89.01%\n",
      "PC4: 3.37%, 92.38%\n",
      "PC5: 1.48%, 93.86%\n",
      "PC6: 1.33%, 95.19%\n",
      "PC7: 0.93%, 96.12%\n",
      "PC8: 0.62%, 96.74%\n",
      "PC9: 0.57%, 97.31%\n",
      "PC10: 0.39%, 97.7%\n",
      "PC11: 0.29%, 97.99%\n",
      "PC12: 0.26%, 98.25%\n",
      "PC13: 0.24%, 98.49%\n",
      "PC14: 0.17%, 98.67%\n",
      "PC15: 0.13%, 98.79%\n",
      "PC16: 0.11%, 98.9%\n",
      "PC17: 0.09%, 98.99%\n",
      "PC18: 0.07%, 99.07%\n",
      "PC19: 0.06%, 99.12%\n",
      "PC20: 0.05%, 99.17%\n",
      "PC21: 0.05%, 99.22%\n",
      "PC22: 0.04%, 99.26%\n",
      "PC23: 0.04%, 99.3%\n",
      "PC24: 0.03%, 99.33%\n",
      "PC25: 0.03%, 99.37%\n",
      "PC26: 0.03%, 99.4%\n",
      "PC27: 0.03%, 99.43%\n",
      "PC28: 0.03%, 99.45%\n",
      "PC29: 0.02%, 99.48%\n",
      "PC30: 0.02%, 99.5%\n",
      "PC31: 0.02%, 99.52%\n",
      "PC32: 0.02%, 99.54%\n",
      "PC33: 0.02%, 99.56%\n",
      "PC34: 0.02%, 99.57%\n",
      "PC35: 0.02%, 99.59%\n",
      "PC36: 0.01%, 99.6%\n",
      "PC37: 0.01%, 99.62%\n",
      "PC38: 0.01%, 99.63%\n",
      "PC39: 0.01%, 99.64%\n",
      "PC40: 0.01%, 99.65%\n",
      "PC41: 0.01%, 99.67%\n",
      "PC42: 0.01%, 99.68%\n",
      "PC43: 0.01%, 99.69%\n",
      "PC44: 0.01%, 99.7%\n",
      "PC45: 0.01%, 99.71%\n",
      "PC46: 0.01%, 99.72%\n",
      "PC47: 0.01%, 99.73%\n",
      "PC48: 0.01%, 99.74%\n",
      "PC49: 0.01%, 99.74%\n",
      "PC50: 0.01%, 99.75%\n",
      "PC51: 0.01%, 99.76%\n",
      "PC52: 0.01%, 99.77%\n",
      "PC53: 0.01%, 99.78%\n",
      "PC54: 0.01%, 99.78%\n",
      "PC55: 0.01%, 99.79%\n",
      "PC56: 0.01%, 99.8%\n",
      "PC57: 0.01%, 99.8%\n",
      "PC58: 0.01%, 99.81%\n",
      "PC59: 0.01%, 99.82%\n",
      "PC60: 0.01%, 99.82%\n",
      "PC61: 0.01%, 99.83%\n",
      "PC62: 0.01%, 99.83%\n",
      "PC63: 0.01%, 99.84%\n",
      "PC64: 0.01%, 99.85%\n",
      "PC65: 0.01%, 99.85%\n",
      "PC66: 0.0%, 99.86%\n",
      "PC67: 0.0%, 99.86%\n",
      "PC68: 0.0%, 99.86%\n",
      "PC69: 0.0%, 99.87%\n",
      "PC70: 0.0%, 99.87%\n",
      "PC71: 0.0%, 99.88%\n",
      "PC72: 0.0%, 99.88%\n",
      "PC73: 0.0%, 99.89%\n",
      "PC74: 0.0%, 99.89%\n",
      "PC75: 0.0%, 99.89%\n",
      "PC76: 0.0%, 99.9%\n",
      "PC77: 0.0%, 99.9%\n",
      "PC78: 0.0%, 99.91%\n",
      "PC79: 0.0%, 99.91%\n",
      "PC80: 0.0%, 99.91%\n",
      "PC81: 0.0%, 99.92%\n",
      "PC82: 0.0%, 99.92%\n",
      "PC83: 0.0%, 99.92%\n",
      "PC84: 0.0%, 99.92%\n",
      "PC85: 0.0%, 99.93%\n",
      "PC86: 0.0%, 99.93%\n",
      "PC87: 0.0%, 99.93%\n",
      "PC88: 0.0%, 99.94%\n",
      "PC89: 0.0%, 99.94%\n",
      "PC90: 0.0%, 99.94%\n",
      "PC91: 0.0%, 99.94%\n",
      "PC92: 0.0%, 99.95%\n",
      "PC93: 0.0%, 99.95%\n",
      "PC94: 0.0%, 99.95%\n",
      "PC95: 0.0%, 99.95%\n",
      "PC96: 0.0%, 99.95%\n",
      "PC97: 0.0%, 99.96%\n",
      "PC98: 0.0%, 99.96%\n",
      "PC99: 0.0%, 99.96%\n",
      "PC100: 0.0%, 99.96%\n",
      "PC101: 0.0%, 99.96%\n",
      "PC102: 0.0%, 99.97%\n",
      "PC103: 0.0%, 99.97%\n",
      "PC104: 0.0%, 99.97%\n",
      "PC105: 0.0%, 99.97%\n",
      "PC106: 0.0%, 99.97%\n",
      "PC107: 0.0%, 99.97%\n",
      "PC108: 0.0%, 99.98%\n",
      "PC109: 0.0%, 99.98%\n",
      "PC110: 0.0%, 99.98%\n",
      "PC111: 0.0%, 99.98%\n",
      "PC112: 0.0%, 99.98%\n",
      "PC113: 0.0%, 99.98%\n",
      "PC114: 0.0%, 99.98%\n",
      "PC115: 0.0%, 99.98%\n",
      "PC116: 0.0%, 99.99%\n",
      "PC117: 0.0%, 99.99%\n",
      "PC118: 0.0%, 99.99%\n",
      "PC119: 0.0%, 99.99%\n",
      "PC120: 0.0%, 99.99%\n",
      "PC121: 0.0%, 99.99%\n",
      "PC122: 0.0%, 99.99%\n",
      "PC123: 0.0%, 99.99%\n",
      "PC124: 0.0%, 99.99%\n",
      "PC125: 0.0%, 99.99%\n",
      "PC126: 0.0%, 99.99%\n",
      "PC127: 0.0%, 99.99%\n",
      "PC128: 0.0%, 99.99%\n",
      "PC129: 0.0%, 99.99%\n",
      "PC130: 0.0%, 99.99%\n",
      "PC131: 0.0%, 100.0%\n",
      "PC132: 0.0%, 100.0%\n",
      "PC133: 0.0%, 100.0%\n",
      "PC134: 0.0%, 100.0%\n",
      "PC135: 0.0%, 100.0%\n",
      "PC136: 0.0%, 100.0%\n",
      "PC137: 0.0%, 100.0%\n",
      "PC138: 0.0%, 100.0%\n",
      "PC139: 0.0%, 100.0%\n",
      "PC140: 0.0%, 100.0%\n",
      "PC141: 0.0%, 100.0%\n",
      "PC142: 0.0%, 100.0%\n",
      "PC143: 0.0%, 100.0%\n",
      "PC144: 0.0%, 100.0%\n",
      "PC145: 0.0%, 100.0%\n",
      "PC146: 0.0%, 100.0%\n",
      "PC147: 0.0%, 100.0%\n",
      "PC148: 0.0%, 100.0%\n",
      "PC149: 0.0%, 100.0%\n",
      "PC150: 0.0%, 100.0%\n",
      "PC151: 0.0%, 100.0%\n",
      "PC152: 0.0%, 100.0%\n",
      "PC153: 0.0%, 100.0%\n",
      "PC154: 0.0%, 100.0%\n",
      "PC155: 0.0%, 100.0%\n",
      "PC156: 0.0%, 100.0%\n",
      "PC157: 0.0%, 100.0%\n",
      "PC158: 0.0%, 100.0%\n",
      "PC159: 0.0%, 100.0%\n",
      "PC160: 0.0%, 100.0%\n",
      "PC161: 0.0%, 100.0%\n",
      "PC162: 0.0%, 100.0%\n",
      "PC163: 0.0%, 100.0%\n",
      "PC164: 0.0%, 100.0%\n",
      "PC165: 0.0%, 100.0%\n",
      "PC166: 0.0%, 100.0%\n",
      "PC167: 0.0%, 100.0%\n",
      "PC168: 0.0%, 100.0%\n",
      "PC169: 0.0%, 100.0%\n",
      "PC170: 0.0%, 100.0%\n",
      "PC171: 0.0%, 100.0%\n",
      "PC172: 0.0%, 100.0%\n",
      "PC173: 0.0%, 100.0%\n",
      "PC174: 0.0%, 100.0%\n",
      "PC175: 0.0%, 100.0%\n",
      "PC176: 0.0%, 100.0%\n",
      "PC177: 0.0%, 100.0%\n",
      "PC178: 0.0%, 100.0%\n",
      "PC179: 0.0%, 100.0%\n",
      "PC180: 0.0%, 100.0%\n",
      "PC181: 0.0%, 100.0%\n",
      "PC182: 0.0%, 100.0%\n",
      "PC183: 0.0%, 100.0%\n",
      "PC184: 0.0%, 100.0%\n",
      "PC185: 0.0%, 100.0%\n",
      "PC186: 0.0%, 100.0%\n",
      "PC187: 0.0%, 100.0%\n",
      "PC188: 0.0%, 100.0%\n",
      "PC189: 0.0%, 100.0%\n",
      "PC190: 0.0%, 100.0%\n",
      "PC191: 0.0%, 100.0%\n",
      "PC192: 0.0%, 100.0%\n",
      "PC193: 0.0%, 100.0%\n",
      "PC194: 0.0%, 100.0%\n",
      "PC195: 0.0%, 100.0%\n",
      "PC196: 0.0%, 100.0%\n",
      "PC197: 0.0%, 100.0%\n",
      "PC198: 0.0%, 100.0%\n",
      "PCA explained variance report saved to ./03_morphometrics_output_cultivated1st_combined/pca_explained_variance_cultivated1st.txt\n",
      "\n",
      "--- Saving PCA model parameters, PC scores, and class labels ---\n",
      "  PCA Components shape: (198, 198)\n",
      "  PCA Mean shape: (198,)\n",
      "  PCA Explained Variance shape: (198,)\n",
      "  PCA Explained Variance Ratio shape: (198,)\n",
      "  Number of PCA components: 198\n",
      "  Original PCA Scores (PCs) shape: (319, 198)\n",
      "  Class Labels (full_name) length: 319\n",
      "PCA parameters saved to ./03_morphometrics_output_cultivated1st_combined/leaf_pca_model_parameters_cultivated1st.h5\n",
      "Original PCA scores, class labels, AND original flattened coordinates saved to ./03_morphometrics_output_cultivated1st_combined/original_pca_scores_and_class_labels_cultivated1st.h5\n",
      "\n",
      "--- Creating Morphospace Plot ---\n",
      "Morphospace plot saved to ./03_morphometrics_output_cultivated1st_combined/morphospace_plot_cultivated1st.png\n",
      "\n",
      "========== Analysis for CULTIVATED1ST Dataset Completed ==========\n",
      "\n",
      "========== Starting Analysis for CULTIVATED2ND Dataset ==========\n",
      "Saving outputs to directory: ./03_morphometrics_output_cultivated2nd_combined/\n",
      "Metadata loaded from: ./01_cultivated2nd_landmarks.csv\n",
      "First 5 rows of loaded metadata:\n",
      "          file            species  px_cm  base_x  base_y   tip_x   tip_y  \\\n",
      "0  AMA1A_a.tif  Erythroxylym coca   28.4  271.00  195.25  127.50  189.00   \n",
      "1  AMA1A_b.tif  Erythroxylym coca   28.4  275.00  202.75  125.00  193.25   \n",
      "2  AMA1A_c.tif  Erythroxylym coca   28.4  271.25  202.50  127.75  194.00   \n",
      "3  AMA1A_d.tif  Erythroxylym coca   28.4  281.00  208.00  118.00  193.00   \n",
      "4  AMA1A_e.tif  Erythroxylym coca   28.4  284.25  210.25  115.50  200.00   \n",
      "\n",
      "  variety plant leaf full_name  type  \n",
      "0     AMA    1A    a   amazona  coca  \n",
      "1     AMA    1A    b   amazona  coca  \n",
      "2     AMA    1A    c   amazona  coca  \n",
      "3     AMA    1A    d   amazona  coca  \n",
      "4     AMA    1A    e   amazona  coca  \n",
      "Found 3253 image files to process from metadata.\n",
      "\n",
      "--- Preprocessing Images and Interpolating Pseudo-Landmarks ---\n",
      "Error processing image BRO1B_k.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image CHA7A_j.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image CHA8M_i.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image DES1B_l.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image DUL1B_g.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image DUL5B_h.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "Error processing image DUL5B_k.tif: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      ". Skipping.\n",
      "--- Calculating GPA Mean ---\n",
      "--- Aligning Leaves to GPA Mean ---\n",
      "--- Visualizing GPA Aligned Shapes ---\n",
      "GPA mean shape plot saved to ./03_morphometrics_output_cultivated2nd_combined/gpa_mean_shape_cultivated2nd.png\n",
      "\n",
      "--- Performing Full PCA and Generating Explained Variance Report ---\n",
      "PC1: 61.07%, 61.07%\n",
      "PC2: 17.0%, 78.06%\n",
      "PC3: 9.46%, 87.52%\n",
      "PC4: 3.03%, 90.55%\n",
      "PC5: 1.79%, 92.34%\n",
      "PC6: 1.19%, 93.53%\n",
      "PC7: 1.05%, 94.58%\n",
      "PC8: 0.68%, 95.26%\n",
      "PC9: 0.62%, 95.88%\n",
      "PC10: 0.51%, 96.39%\n",
      "PC11: 0.41%, 96.8%\n",
      "PC12: 0.31%, 97.11%\n",
      "PC13: 0.3%, 97.41%\n",
      "PC14: 0.26%, 97.67%\n",
      "PC15: 0.21%, 97.88%\n",
      "PC16: 0.19%, 98.07%\n",
      "PC17: 0.16%, 98.23%\n",
      "PC18: 0.13%, 98.35%\n",
      "PC19: 0.12%, 98.47%\n",
      "PC20: 0.11%, 98.57%\n",
      "PC21: 0.09%, 98.66%\n",
      "PC22: 0.07%, 98.74%\n",
      "PC23: 0.07%, 98.81%\n",
      "PC24: 0.07%, 98.88%\n",
      "PC25: 0.06%, 98.93%\n",
      "PC26: 0.05%, 98.98%\n",
      "PC27: 0.05%, 99.03%\n",
      "PC28: 0.05%, 99.08%\n",
      "PC29: 0.04%, 99.12%\n",
      "PC30: 0.04%, 99.16%\n",
      "PC31: 0.03%, 99.19%\n",
      "PC32: 0.03%, 99.23%\n",
      "PC33: 0.03%, 99.25%\n",
      "PC34: 0.03%, 99.28%\n",
      "PC35: 0.03%, 99.31%\n",
      "PC36: 0.02%, 99.33%\n",
      "PC37: 0.02%, 99.35%\n",
      "PC38: 0.02%, 99.38%\n",
      "PC39: 0.02%, 99.4%\n",
      "PC40: 0.02%, 99.42%\n",
      "PC41: 0.02%, 99.43%\n",
      "PC42: 0.02%, 99.45%\n",
      "PC43: 0.02%, 99.47%\n",
      "PC44: 0.02%, 99.48%\n",
      "PC45: 0.01%, 99.49%\n",
      "PC46: 0.01%, 99.51%\n",
      "PC47: 0.01%, 99.52%\n",
      "PC48: 0.01%, 99.53%\n",
      "PC49: 0.01%, 99.54%\n",
      "PC50: 0.01%, 99.56%\n",
      "PC51: 0.01%, 99.57%\n",
      "PC52: 0.01%, 99.58%\n",
      "PC53: 0.01%, 99.59%\n",
      "PC54: 0.01%, 99.6%\n",
      "PC55: 0.01%, 99.61%\n",
      "PC56: 0.01%, 99.62%\n",
      "PC57: 0.01%, 99.62%\n",
      "PC58: 0.01%, 99.63%\n",
      "PC59: 0.01%, 99.64%\n",
      "PC60: 0.01%, 99.65%\n",
      "PC61: 0.01%, 99.66%\n",
      "PC62: 0.01%, 99.67%\n",
      "PC63: 0.01%, 99.67%\n",
      "PC64: 0.01%, 99.68%\n",
      "PC65: 0.01%, 99.69%\n",
      "PC66: 0.01%, 99.69%\n",
      "PC67: 0.01%, 99.7%\n",
      "PC68: 0.01%, 99.71%\n",
      "PC69: 0.01%, 99.72%\n",
      "PC70: 0.01%, 99.72%\n",
      "PC71: 0.01%, 99.73%\n",
      "PC72: 0.01%, 99.73%\n",
      "PC73: 0.01%, 99.74%\n",
      "PC74: 0.01%, 99.75%\n",
      "PC75: 0.01%, 99.75%\n",
      "PC76: 0.01%, 99.76%\n",
      "PC77: 0.01%, 99.76%\n",
      "PC78: 0.01%, 99.77%\n",
      "PC79: 0.01%, 99.78%\n",
      "PC80: 0.01%, 99.78%\n",
      "PC81: 0.01%, 99.79%\n",
      "PC82: 0.01%, 99.79%\n",
      "PC83: 0.01%, 99.8%\n",
      "PC84: 0.01%, 99.8%\n",
      "PC85: 0.01%, 99.81%\n",
      "PC86: 0.01%, 99.81%\n",
      "PC87: 0.0%, 99.82%\n",
      "PC88: 0.0%, 99.82%\n",
      "PC89: 0.0%, 99.83%\n",
      "PC90: 0.0%, 99.83%\n",
      "PC91: 0.0%, 99.84%\n",
      "PC92: 0.0%, 99.84%\n",
      "PC93: 0.0%, 99.85%\n",
      "PC94: 0.0%, 99.85%\n",
      "PC95: 0.0%, 99.86%\n",
      "PC96: 0.0%, 99.86%\n",
      "PC97: 0.0%, 99.86%\n",
      "PC98: 0.0%, 99.87%\n",
      "PC99: 0.0%, 99.87%\n",
      "PC100: 0.0%, 99.88%\n",
      "PC101: 0.0%, 99.88%\n",
      "PC102: 0.0%, 99.88%\n",
      "PC103: 0.0%, 99.89%\n",
      "PC104: 0.0%, 99.89%\n",
      "PC105: 0.0%, 99.9%\n",
      "PC106: 0.0%, 99.9%\n",
      "PC107: 0.0%, 99.9%\n",
      "PC108: 0.0%, 99.91%\n",
      "PC109: 0.0%, 99.91%\n",
      "PC110: 0.0%, 99.91%\n",
      "PC111: 0.0%, 99.92%\n",
      "PC112: 0.0%, 99.92%\n",
      "PC113: 0.0%, 99.92%\n",
      "PC114: 0.0%, 99.93%\n",
      "PC115: 0.0%, 99.93%\n",
      "PC116: 0.0%, 99.93%\n",
      "PC117: 0.0%, 99.94%\n",
      "PC118: 0.0%, 99.94%\n",
      "PC119: 0.0%, 99.94%\n",
      "PC120: 0.0%, 99.95%\n",
      "PC121: 0.0%, 99.95%\n",
      "PC122: 0.0%, 99.95%\n",
      "PC123: 0.0%, 99.96%\n",
      "PC124: 0.0%, 99.96%\n",
      "PC125: 0.0%, 99.96%\n",
      "PC126: 0.0%, 99.96%\n",
      "PC127: 0.0%, 99.96%\n",
      "PC128: 0.0%, 99.97%\n",
      "PC129: 0.0%, 99.97%\n",
      "PC130: 0.0%, 99.97%\n",
      "PC131: 0.0%, 99.97%\n",
      "PC132: 0.0%, 99.97%\n",
      "PC133: 0.0%, 99.97%\n",
      "PC134: 0.0%, 99.98%\n",
      "PC135: 0.0%, 99.98%\n",
      "PC136: 0.0%, 99.98%\n",
      "PC137: 0.0%, 99.98%\n",
      "PC138: 0.0%, 99.98%\n",
      "PC139: 0.0%, 99.98%\n",
      "PC140: 0.0%, 99.98%\n",
      "PC141: 0.0%, 99.98%\n",
      "PC142: 0.0%, 99.98%\n",
      "PC143: 0.0%, 99.98%\n",
      "PC144: 0.0%, 99.99%\n",
      "PC145: 0.0%, 99.99%\n",
      "PC146: 0.0%, 99.99%\n",
      "PC147: 0.0%, 99.99%\n",
      "PC148: 0.0%, 99.99%\n",
      "PC149: 0.0%, 99.99%\n",
      "PC150: 0.0%, 99.99%\n",
      "PC151: 0.0%, 99.99%\n",
      "PC152: 0.0%, 99.99%\n",
      "PC153: 0.0%, 99.99%\n",
      "PC154: 0.0%, 99.99%\n",
      "PC155: 0.0%, 99.99%\n",
      "PC156: 0.0%, 99.99%\n",
      "PC157: 0.0%, 99.99%\n",
      "PC158: 0.0%, 99.99%\n",
      "PC159: 0.0%, 99.99%\n",
      "PC160: 0.0%, 99.99%\n",
      "PC161: 0.0%, 99.99%\n",
      "PC162: 0.0%, 99.99%\n",
      "PC163: 0.0%, 99.99%\n",
      "PC164: 0.0%, 100.0%\n",
      "PC165: 0.0%, 100.0%\n",
      "PC166: 0.0%, 100.0%\n",
      "PC167: 0.0%, 100.0%\n",
      "PC168: 0.0%, 100.0%\n",
      "PC169: 0.0%, 100.0%\n",
      "PC170: 0.0%, 100.0%\n",
      "PC171: 0.0%, 100.0%\n",
      "PC172: 0.0%, 100.0%\n",
      "PC173: 0.0%, 100.0%\n",
      "PC174: 0.0%, 100.0%\n",
      "PC175: 0.0%, 100.0%\n",
      "PC176: 0.0%, 100.0%\n",
      "PC177: 0.0%, 100.0%\n",
      "PC178: 0.0%, 100.0%\n",
      "PC179: 0.0%, 100.0%\n",
      "PC180: 0.0%, 100.0%\n",
      "PC181: 0.0%, 100.0%\n",
      "PC182: 0.0%, 100.0%\n",
      "PC183: 0.0%, 100.0%\n",
      "PC184: 0.0%, 100.0%\n",
      "PC185: 0.0%, 100.0%\n",
      "PC186: 0.0%, 100.0%\n",
      "PC187: 0.0%, 100.0%\n",
      "PC188: 0.0%, 100.0%\n",
      "PC189: 0.0%, 100.0%\n",
      "PC190: 0.0%, 100.0%\n",
      "PC191: 0.0%, 100.0%\n",
      "PC192: 0.0%, 100.0%\n",
      "PC193: 0.0%, 100.0%\n",
      "PC194: 0.0%, 100.0%\n",
      "PC195: 0.0%, 100.0%\n",
      "PC196: 0.0%, 100.0%\n",
      "PC197: 0.0%, 100.0%\n",
      "PC198: 0.0%, 100.0%\n",
      "PCA explained variance report saved to ./03_morphometrics_output_cultivated2nd_combined/pca_explained_variance_cultivated2nd.txt\n",
      "\n",
      "--- Saving PCA model parameters, PC scores, and class labels ---\n",
      "  PCA Components shape: (198, 198)\n",
      "  PCA Mean shape: (198,)\n",
      "  PCA Explained Variance shape: (198,)\n",
      "  PCA Explained Variance Ratio shape: (198,)\n",
      "  Number of PCA components: 198\n",
      "  Original PCA Scores (PCs) shape: (3246, 198)\n",
      "  Class Labels (full_name) length: 3246\n",
      "PCA parameters saved to ./03_morphometrics_output_cultivated2nd_combined/leaf_pca_model_parameters_cultivated2nd.h5\n",
      "Original PCA scores, class labels, AND original flattened coordinates saved to ./03_morphometrics_output_cultivated2nd_combined/original_pca_scores_and_class_labels_cultivated2nd.h5\n",
      "\n",
      "--- Creating Morphospace Plot ---\n",
      "Morphospace plot saved to ./03_morphometrics_output_cultivated2nd_combined/morphospace_plot_cultivated2nd.png\n",
      "\n",
      "========== Analysis for CULTIVATED2ND Dataset Completed ==========\n",
      "\n",
      "All analyses for both datasets completed and outputs saved to their respective directories.\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "### LOAD IN MODULES ###\n",
    "#######################\n",
    "\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as multitest\n",
    "import itertools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "import phate\n",
    "import scprep\n",
    "import h5py\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#################\n",
    "### FUNCTIONS ###\n",
    "#################\n",
    "\n",
    "def angle_between(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    define a function to find the angle between 3 points anti-clockwise in degrees, p2 being the vertex\n",
    "    inputs: three angle points, as tuples\n",
    "    output: angle in degrees\n",
    "    \"\"\"\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    deg1 = (360 + math.degrees(math.atan2(x1 - x2, y1 - y2))) % 360\n",
    "    deg2 = (360 + math.degrees(math.atan2(x3 - x2, y3 - y2))) % 360\n",
    "    return deg2 - deg1 if deg1 <= deg2 else 360 - (deg1 - deg2)\n",
    "\n",
    "def rotate_points(xvals, yvals, degrees):\n",
    "    \"\"\"\"\n",
    "    define a function to rotate 2D x and y coordinate points around the origin\n",
    "    inputs: x and y vals (can take pandas dataframe columns) and the degrees (positive, anticlockwise) to rotate\n",
    "    outputs: rotated and y vals\n",
    "    \"\"\"\n",
    "    angle_to_move = 90 - degrees\n",
    "    rads = np.deg2rad(angle_to_move)\n",
    "\n",
    "    new_xvals = xvals * np.cos(rads) - yvals * np.sin(rads)\n",
    "    new_yvals = xvals * np.sin(rads) + yvals * np.cos(rads)\n",
    "\n",
    "    return new_xvals, new_yvals\n",
    "\n",
    "def interpolation(x, y, number):\n",
    "    \"\"\"\n",
    "    define a function to return equally spaced, interpolated points for a given polyline\n",
    "    inputs: arrays of x and y values for a polyline, number of points to interpolate\n",
    "    ouputs: interpolated points along the polyline, inclusive of start and end points\n",
    "    \"\"\"\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        if np.all(x == x[0]) and np.all(y == y[0]):\n",
    "            return np.full(number, x[0]), np.full(number, y[0])\n",
    "        elif len(x) == 1:\n",
    "            return np.full(number, x[0]), np.full(number, y[0])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    distance = np.cumsum(np.sqrt(np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2))\n",
    "\n",
    "    if distance[-1] == 0:\n",
    "        return np.full(number, x[0]), np.full(number, y[0])\n",
    "\n",
    "    distance = distance / distance[-1]\n",
    "\n",
    "    fx, fy = interp1d(distance, x), interp1d(distance, y)\n",
    "\n",
    "    alpha = np.linspace(0, 1, number)\n",
    "    x_regular, y_regular = fx(alpha), fy(alpha)\n",
    "\n",
    "    return x_regular, y_regular\n",
    "\n",
    "def euclid_dist(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    define a function to return the euclidean distance between two points\n",
    "    inputs: x and y values of the two points\n",
    "    output: the eulidean distance\n",
    "    \"\"\"\n",
    "    return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def poly_area(x, y):\n",
    "    \"\"\"\n",
    "    define a function to calculate the area of a polygon using the shoelace algorithm\n",
    "    inputs: separate numpy arrays of x and y coordinate values\n",
    "    outputs: the area of the polygon\n",
    "    \"\"\"\n",
    "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
    "\n",
    "def gpa_mean(leaf_arr, landmark_num, dim_num):\n",
    "    \"\"\"\n",
    "    define a function that given an array of landmark data returns the Generalized Procrustes Analysis mean\n",
    "    inputs: a 3 dimensional array of samples by landmarks by coordinate values, number of landmarks, number of dimensions\n",
    "    output: an array of the Generalized Procrustes Analysis mean shape\n",
    "    \"\"\"\n",
    "    ref_ind = 0\n",
    "    ref_shape = leaf_arr[ref_ind, :, :]\n",
    "    mean_diff = 10**(-30)\n",
    "    old_mean = ref_shape\n",
    "    d = 1000000\n",
    "\n",
    "    while d > mean_diff:\n",
    "        arr = np.zeros(((len(leaf_arr)), landmark_num, dim_num))\n",
    "        for i in range(len(leaf_arr)):\n",
    "            s1, s2, distance = procrustes(old_mean, leaf_arr[i])\n",
    "            arr[i] = s2\n",
    "        new_mean = np.mean(arr, axis=(0))\n",
    "        s1, s2, d = procrustes(old_mean, new_mean)\n",
    "        old_mean = new_mean\n",
    "    return new_mean\n",
    "\n",
    "def run_morphometric_analysis(metadata_file_path, image_data_dir, output_base_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Runs the full morphometric analysis pipeline for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        metadata_file_path (str): Path to the CSV metadata file.\n",
    "        image_data_dir (str): Path to the directory containing image files.\n",
    "        output_base_dir (str): Base directory where all outputs for this dataset will be saved.\n",
    "        dataset_name (str): A descriptive name for the dataset (e.g., \"cultivated1st\", \"cultivated2nd\")\n",
    "                            used in print statements and specific output filenames.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*10} Starting Analysis for {dataset_name.upper()} Dataset {'='*10}\")\n",
    "\n",
    "    # --- Configuration and Inputs (now passed as arguments or derived) ---\n",
    "    # Parameters for Preprocessing\n",
    "    HIGH_RES_INTERPOLATION_POINTS = 10000\n",
    "    FINAL_PSEUDO_LANDMARKS_PER_SIDE = 50\n",
    "    NUM_LANDMARKS = (FINAL_PSEUDO_LANDMARKS_PER_SIDE * 2) - 1\n",
    "    NUM_DIMENSIONS = 2\n",
    "\n",
    "    # Parameters for Morphospace Visualization (2-Component PCA)\n",
    "    MORPHOSPACE_PLOT_LENGTH = 10\n",
    "    MORPHOSPACE_PLOT_WIDTH = 10\n",
    "    MORPHOSPACE_PC1_INTERVALS = 20\n",
    "    MORPHOSPACE_PC2_INTERVALS = 6\n",
    "    MORPHOSPACE_HUE_COLUMN = \"full_name\" # Changed from \"type\" to \"full_name\"\n",
    "    EIGENLEAF_SCALE = 0.08\n",
    "    EIGENLEAF_COLOR = \"lightgray\"\n",
    "    EIGENLEAF_ALPHA = 0.5\n",
    "    POINT_SIZE = 80\n",
    "    POINT_LINEWIDTH = 0\n",
    "    POINT_ALPHA = 0.6\n",
    "    AXIS_LABEL_FONTSIZE = 12\n",
    "    AXIS_TICK_FONTSIZE = 8\n",
    "    FACE_COLOR = \"white\"\n",
    "    GRID_ALPHA = 0.5\n",
    "\n",
    "    # Parameters for Output Files\n",
    "    GPA_MEAN_SHAPE_PLOT_FILENAME = f\"gpa_mean_shape_{dataset_name}.png\"\n",
    "    PCA_EXPLAINED_VARIANCE_REPORT_FILENAME = f\"pca_explained_variance_{dataset_name}.txt\"\n",
    "    MORPHOSPACE_PLOT_FILENAME = f\"morphospace_plot_{dataset_name}.png\"\n",
    "    PCA_PARAMS_H5_FILENAME = f\"leaf_pca_model_parameters_{dataset_name}.h5\"\n",
    "    ORIGINAL_PCA_SCORES_AND_LABELS_H5_FILENAME = f\"original_pca_scores_and_class_labels_{dataset_name}.h5\"\n",
    "    CLASS_LABEL_COLUMN_FOR_SAVING = \"full_name\" # Changed from \"type\" to \"full_name\"\n",
    "\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "    print(f\"Saving outputs to directory: {output_base_dir}\")\n",
    "\n",
    "    # --- Read in Metadata ---\n",
    "    mdata = pd.read_csv(metadata_file_path)\n",
    "    print(f\"Metadata loaded from: {metadata_file_path}\")\n",
    "    print(\"First 5 rows of loaded metadata:\")\n",
    "    print(mdata.head())\n",
    "\n",
    "    # --- Make a list of image file names ---\n",
    "    file_names = mdata['file'].tolist()\n",
    "    file_names.sort()\n",
    "    print(f\"Found {len(file_names)} image files to process from metadata.\")\n",
    "\n",
    "    # --- Interpolate Points Creating Pseudo-Landmarks and Pre-process ---\n",
    "    print(\"\\n--- Preprocessing Images and Interpolating Pseudo-Landmarks ---\")\n",
    "    \n",
    "    # Filter out rows with missing image files *before* the loop to avoid incomplete arrays\n",
    "    existing_image_files = set(f for f in os.listdir(image_data_dir) if os.path.isfile(os.path.join(image_data_dir, f)))\n",
    "    \n",
    "    valid_rows_indices = []\n",
    "    processed_points_list = [] \n",
    "\n",
    "    for lf_idx, row in mdata.iterrows():\n",
    "        curr_image_filename = row[\"file\"]\n",
    "        img_path = os.path.join(image_data_dir, curr_image_filename)\n",
    "\n",
    "        if curr_image_filename not in existing_image_files:\n",
    "            print(f\"Warning: Image file not found at {img_path}. Skipping and will exclude from analysis.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2GRAY))\n",
    "            contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            x_conts = []\n",
    "            y_conts = []\n",
    "            areas_conts = []\n",
    "            for c in contours:\n",
    "                x_vals = [pt[0][0] for pt in c]\n",
    "                y_vals = [pt[0][1] for pt in c]\n",
    "                area = (max(x_vals) - min(x_vals)) * (max(y_vals) - min(y_vals))\n",
    "                x_conts.append(x_vals)\n",
    "                y_conts.append(y_vals)\n",
    "                areas_conts.append(area)\n",
    "\n",
    "            if not areas_conts:\n",
    "                print(f\"Warning: No contours found for image {curr_image_filename}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            area_inds = np.flip(np.argsort(areas_conts))\n",
    "            sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:]\n",
    "            sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:]\n",
    "\n",
    "            high_res_x, high_res_y = interpolation(np.array(sorted_x_conts[0], dtype=np.float32),\n",
    "                                                   np.array(sorted_y_conts[0], dtype=np.float32), HIGH_RES_INTERPOLATION_POINTS)\n",
    "\n",
    "            base_pt = np.array((row[\"base_x\"], row[\"base_y\"]))\n",
    "            tip_pt = np.array((row[\"tip_x\"], row[\"tip_y\"]))\n",
    "\n",
    "            base_dists = [euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt]) for pt in range(len(high_res_x))]\n",
    "            tip_dists = [euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt]) for pt in range(len(high_res_x))]\n",
    "\n",
    "            base_ind = np.argmin(base_dists)\n",
    "            tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "            high_res_x = np.concatenate((high_res_x[base_ind:], high_res_x[:base_ind]))\n",
    "            high_res_y = np.concatenate((high_res_y[base_ind:], high_res_y[:base_ind]))\n",
    "\n",
    "            new_tip_dists = [euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt_idx], high_res_y[pt_idx]) for pt_idx in range(len(high_res_x))]\n",
    "            tip_ind_new = np.argmin(new_tip_dists)\n",
    "\n",
    "            lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "            left_segment = lf_contour[0:tip_ind_new + 1, :]\n",
    "            right_segment = np.concatenate((lf_contour[tip_ind_new:, :], lf_contour[0:1, :]), axis=0)\n",
    "\n",
    "            if len(left_segment) < 2 or len(right_segment) < 2:\n",
    "                print(f\"Warning: Segments for image {curr_image_filename} are too short for interpolation. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            left_inter_x, left_inter_y = interpolation(left_segment[:, 0], left_segment[:, 1], FINAL_PSEUDO_LANDMARKS_PER_SIDE)\n",
    "            right_inter_x, right_inter_y = interpolation(right_segment[:, 0], right_segment[:, 1], FINAL_PSEUDO_LANDMARKS_PER_SIDE)\n",
    "\n",
    "            left_inter_x = np.delete(left_inter_x, -1)\n",
    "            left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "            lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "            lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "            lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "            if lf_pts.shape[0] != NUM_LANDMARKS:\n",
    "                print(f\"Warning: Leaf {curr_image_filename} generated {lf_pts.shape[0]} landmarks, expected {NUM_LANDMARKS}. Check interpolation logic.\")\n",
    "                continue\n",
    "\n",
    "            tip_point = lf_pts[FINAL_PSEUDO_LANDMARKS_PER_SIDE - 1, :]\n",
    "            base_point = lf_pts[0, :]\n",
    "\n",
    "            ang = angle_between(tip_point, base_point, (base_point[0] + 1, base_point[1]))\n",
    "\n",
    "            rot_x, rot_y = rotate_points(lf_pts[:, 0], lf_pts[:, 1], ang)\n",
    "            rot_pts = np.column_stack((rot_x, rot_y))\n",
    "\n",
    "            processed_points_list.append(rot_pts)\n",
    "            valid_rows_indices.append(lf_idx)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {curr_image_filename}: {e}. Skipping.\")\n",
    "            continue\n",
    "    \n",
    "    # Rebuild mdata and cult_cm_arr with only successfully processed images\n",
    "    mdata = mdata.iloc[valid_rows_indices].reset_index(drop=True)\n",
    "    cult_cm_arr = np.array(processed_points_list)\n",
    "\n",
    "    if cult_cm_arr.shape[0] == 0:\n",
    "        print(f\"No valid images processed for {dataset_name}. Exiting analysis for this dataset.\")\n",
    "        return\n",
    "\n",
    "    # --- Calculate GPA Mean ---\n",
    "    print(\"--- Calculating GPA Mean ---\")\n",
    "    mean_shape = gpa_mean(cult_cm_arr, NUM_LANDMARKS, NUM_DIMENSIONS)\n",
    "\n",
    "    # --- Align Leaves to GPA Mean ---\n",
    "    print(\"--- Aligning Leaves to GPA Mean ---\")\n",
    "    proc_arr = np.zeros(np.shape(cult_cm_arr))\n",
    "    for i in range(len(cult_cm_arr)):\n",
    "        s1, s2, distance = procrustes(mean_shape, cult_cm_arr[i, :, :])\n",
    "        proc_arr[i] = s2\n",
    "\n",
    "    # --- Visualize GPA Aligned Shapes and Mean ---\n",
    "    print(\"--- Visualizing GPA Aligned Shapes ---\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(len(proc_arr)):\n",
    "        plt.plot(proc_arr[i, :, 0], proc_arr[i, :, 1], c=\"k\", alpha=0.08)\n",
    "    plt.plot(np.mean(proc_arr, axis=0)[:, 0], np.mean(proc_arr, axis=0)[:, 1], c=\"magenta\")\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Procrustes Aligned Leaf Shapes and GPA Mean ({dataset_name.replace('_', ' ').title()})\")\n",
    "    plt.savefig(os.path.join(output_base_dir, GPA_MEAN_SHAPE_PLOT_FILENAME))\n",
    "    plt.close()\n",
    "    print(f\"GPA mean shape plot saved to {os.path.join(output_base_dir, GPA_MEAN_SHAPE_PLOT_FILENAME)}\")\n",
    "\n",
    "    # --- Calculate Percent Variance All PCs ---\n",
    "    print(\"\\n--- Performing Full PCA and Generating Explained Variance Report ---\")\n",
    "    flat_arr = proc_arr.reshape(np.shape(proc_arr)[0], np.shape(proc_arr)[1] * np.shape(proc_arr)[2])\n",
    "\n",
    "    max_pc_components = min(flat_arr.shape[0], flat_arr.shape[1])\n",
    "    pca = PCA(n_components=max_pc_components)\n",
    "    PCs = pca.fit_transform(flat_arr)\n",
    "\n",
    "    pca_explained_variance_filepath = os.path.join(output_base_dir, PCA_EXPLAINED_VARIANCE_REPORT_FILENAME)\n",
    "    with open(pca_explained_variance_filepath, 'w') as f:\n",
    "        f.write(f\"PCA Explained Variance Report ({dataset_name.replace('_', ' ').title()} Dataset):\\n\")\n",
    "        f.write(f\"Total Samples: {flat_arr.shape[0]}\\n\")\n",
    "        f.write(f\"Total Features (landmarks * dimensions): {flat_arr.shape[1]}\\n\")\n",
    "        f.write(f\"Number of PCs Calculated: {pca.n_components_}\\n\\n\")\n",
    "        f.write(\"PC: var, overall\\n\")\n",
    "        for i in range(len(pca.explained_variance_ratio_)):\n",
    "            pc_variance = round(pca.explained_variance_ratio_[i] * 100, 2)\n",
    "            cumulative_variance = round(pca.explained_variance_ratio_.cumsum()[i] * 100, 2)\n",
    "            line = f\"PC{i+1}: {pc_variance}%, {cumulative_variance}%\\n\"\n",
    "            print(line.strip())\n",
    "            f.write(line)\n",
    "    print(f\"PCA explained variance report saved to {pca_explained_variance_filepath}\")\n",
    "\n",
    "    # --- Save PCA Model Parameters, PC Scores, and Class Labels ---\n",
    "    print(\"\\n--- Saving PCA model parameters, PC scores, and class labels ---\")\n",
    "    pca_components = pca.components_\n",
    "    pca_mean = pca.mean_\n",
    "    pca_explained_variance = pca.explained_variance_\n",
    "    pca_explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    n_pca_components = pca.n_components_\n",
    "\n",
    "    print(f\"  PCA Components shape: {pca_components.shape}\")\n",
    "    print(f\"  PCA Mean shape: {pca_mean.shape}\")\n",
    "    print(f\"  PCA Explained Variance shape: {pca_explained_variance.shape}\")\n",
    "    print(f\"  PCA Explained Variance Ratio shape: {pca_explained_variance_ratio.shape}\")\n",
    "    print(f\"  Number of PCA components: {n_pca_components}\")\n",
    "    print(f\"  Original PCA Scores (PCs) shape: {PCs.shape}\")\n",
    "    print(f\"  Class Labels ({CLASS_LABEL_COLUMN_FOR_SAVING}) length: {len(mdata[CLASS_LABEL_COLUMN_FOR_SAVING])}\")\n",
    "\n",
    "    pca_params_filepath = os.path.join(output_base_dir, PCA_PARAMS_H5_FILENAME)\n",
    "    with h5py.File(pca_params_filepath, 'w') as f:\n",
    "        f.create_dataset('components', data=pca_components, compression=\"gzip\")\n",
    "        f.create_dataset('mean', data=pca_mean, compression=\"gzip\")\n",
    "        f.create_dataset('explained_variance', data=pca_explained_variance, compression=\"gzip\")\n",
    "        f.create_dataset('explained_variance_ratio', data=pca_explained_variance_ratio, compression=\"gzip\")\n",
    "        f.attrs['n_components'] = n_pca_components\n",
    "    print(f\"PCA parameters saved to {pca_params_filepath}\")\n",
    "\n",
    "    pca_scores_labels_filepath = os.path.join(output_base_dir, ORIGINAL_PCA_SCORES_AND_LABELS_H5_FILENAME)\n",
    "    with h5py.File(pca_scores_labels_filepath, 'w') as f:\n",
    "        f.create_dataset('pca_scores', data=PCs, compression=\"gzip\")\n",
    "        f.create_dataset('class_labels', data=np.array(mdata[CLASS_LABEL_COLUMN_FOR_SAVING]).astype('S'), compression=\"gzip\")\n",
    "        f.create_dataset('original_flattened_coords', data=flat_arr, compression=\"gzip\")\n",
    "    print(f\"Original PCA scores, class labels, AND original flattened coordinates saved to {pca_scores_labels_filepath}\")\n",
    "\n",
    "    # --- Create Morphospace ---\n",
    "    print(\"\\n--- Creating Morphospace Plot ---\")\n",
    "    morphospace_pca = PCA(n_components=2)\n",
    "    morphospace_PCs = morphospace_pca.fit_transform(flat_arr)\n",
    "\n",
    "    mdata[\"PC1\"] = morphospace_PCs[:, 0]\n",
    "    mdata[\"PC2\"] = morphospace_PCs[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(MORPHOSPACE_PLOT_LENGTH, MORPHOSPACE_PLOT_WIDTH))\n",
    "    plt.gca().set_facecolor(FACE_COLOR)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "\n",
    "    PC1_vals = np.linspace(np.min(PCs[:, 0]), np.max(PCs[:, 0]), MORPHOSPACE_PC1_INTERVALS)\n",
    "    PC2_vals = np.linspace(np.min(PCs[:, 1]), np.max(PCs[:, 1]), MORPHOSPACE_PC2_INTERVALS)\n",
    "\n",
    "    for i in PC1_vals:\n",
    "        for j in PC2_vals:\n",
    "            inv_leaf = morphospace_pca.inverse_transform(np.array([i, j]))\n",
    "            inv_leaf_coords = inv_leaf.reshape(NUM_LANDMARKS, NUM_DIMENSIONS)\n",
    "\n",
    "            inv_x = inv_leaf_coords[:, 0]\n",
    "            inv_y = inv_leaf_coords[:, 1]\n",
    "\n",
    "            plt.fill(inv_x * EIGENLEAF_SCALE + i, inv_y * EIGENLEAF_SCALE + j,\n",
    "                     c=EIGENLEAF_COLOR, alpha=EIGENLEAF_ALPHA)\n",
    "\n",
    "    sns.scatterplot(data=mdata, x=\"PC1\", y=\"PC2\", hue=MORPHOSPACE_HUE_COLUMN,\n",
    "                    s=POINT_SIZE, linewidth=POINT_LINEWIDTH, alpha=POINT_ALPHA)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "    xlab = f\"PC1, {round(pca.explained_variance_ratio_[0] * 100, 1)}%\"\n",
    "    ylab = f\"PC2, {round(pca.explained_variance_ratio_[1] * 100, 1)}%\"\n",
    "    plt.xlabel(xlab, fontsize=AXIS_LABEL_FONTSIZE)\n",
    "    plt.ylabel(ylab, fontsize=AXIS_LABEL_FONTSIZE)\n",
    "    plt.xticks(fontsize=AXIS_TICK_FONTSIZE)\n",
    "    plt.yticks(fontsize=AXIS_TICK_FONTSIZE)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "    plt.savefig(os.path.join(output_base_dir, MORPHOSPACE_PLOT_FILENAME), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Morphospace plot saved to {os.path.join(output_base_dir, MORPHOSPACE_PLOT_FILENAME)}\")\n",
    "\n",
    "    print(f\"\\n{'='*10} Analysis for {dataset_name.upper()} Dataset Completed {'='*10}\")\n",
    "\n",
    "\n",
    "# --- Define paths relative to the current notebook (COCA_PROJECT/data/CULTIVATED2ND/) ---\n",
    "# Paths for CULTIVATED1ST dataset\n",
    "CULTIVATED1ST_METADATA_FILE = \"../CULTIVATED1ST/01_cultivated1st_landmarks.csv\"\n",
    "CULTIVATED1ST_IMAGE_DIR = \"../CULTIVATED1ST/00_cultivated1st_data/\"\n",
    "CULTIVATED1ST_OUTPUT_DIR = \"./03_morphometrics_output_cultivated1st_combined/\" # New unique output dir\n",
    "\n",
    "# Paths for CULTIVATED2ND dataset\n",
    "CULTIVATED2ND_METADATA_FILE = \"./01_cultivated2nd_landmarks.csv\" # This is in the current directory\n",
    "CULTIVATED2ND_IMAGE_DIR = \"./00_cultivated2nd_data/\" # This is in the current directory\n",
    "CULTIVATED2ND_OUTPUT_DIR = \"./03_morphometrics_output_cultivated2nd_combined/\" # New unique output dir\n",
    "\n",
    "# --- Run analysis for CULTIVATED1ST ---\n",
    "run_morphometric_analysis(\n",
    "    metadata_file_path=CULTIVATED1ST_METADATA_FILE,\n",
    "    image_data_dir=CULTIVATED1ST_IMAGE_DIR,\n",
    "    output_base_dir=CULTIVATED1ST_OUTPUT_DIR,\n",
    "    dataset_name=\"cultivated1st\"\n",
    ")\n",
    "\n",
    "# --- Run analysis for CULTIVATED2ND ---\n",
    "run_morphometric_analysis(\n",
    "    metadata_file_path=CULTIVATED2ND_METADATA_FILE,\n",
    "    image_data_dir=CULTIVATED2ND_IMAGE_DIR,\n",
    "    output_base_dir=CULTIVATED2ND_OUTPUT_DIR,\n",
    "    dataset_name=\"cultivated2nd\"\n",
    ")\n",
    "\n",
    "print(\"\\nAll analyses for both datasets completed and outputs saved to their respective directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcc7b2-5e36-4ae0-a161-14ac2c61548b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
