### Methods: Convolutional Neural Network for Binary Collection Classification

For the task of classifying leaf images into their respective collection origins (either "Cultivated 1st" or "Cultivated 2nd"), a dedicated Convolutional Neural Network (CNN) model, `LeafCNN`, was developed using PyTorch. This model was designed to perform binary classification, outputting a single logit that indicates the probability of belonging to one collection versus the other. All analyses were conducted with a global random seed set to 42 for reproducibility.

#### CNN Architecture and Parameters

The `LeafCNN` architecture processes two-channel input images (Euler Characteristic Transform data and binary shape mask) of dimensions 256x256 pixels. Its design comprises:

* **Feature Extraction Blocks:** Three sequential blocks, each consisting of a `Conv2d` layer (3x3 kernel, 1-pixel padding), followed by `BatchNorm2d` for regularization, a `ReLU` activation function, and a `MaxPool2d` layer (2x2 kernel, stride 2) for downsampling. The number of filters progressively increases across these blocks: 32 in the first, 64 in the second, and 128 in the third.
* **Classifier Head:** The flattened output from the feature extraction layers is fed into a fully connected component. This includes a `Linear` layer with 512 units and `ReLU` activation, followed by a `Dropout` layer with a 0.5 probability to prevent overfitting. The final layer is a `Linear` layer with a single output unit, producing the logit for binary classification.

#### Model Training and Evaluation

Model training employed a 5-fold stratified cross-validation strategy. For each fold:

* **Data Split:** The validation set consisted exclusively of real leaf samples from that fold's stratified split. The training set comprised all available synthetic samples combined with the real leaf samples from the training split.
* **Loss Function:** Given the binary classification task, `BCEWithLogitsLoss` (Binary Cross-Entropy with Logits Loss) was used as the criterion. To address potential class imbalance between the two collections, a `pos_weight` parameter was dynamically calculated and applied to the loss function, balancing the contribution of positive and negative classes based on their respective counts in the combined training data.
* **Optimizer and Scheduler:** The Adam optimizer was used with an initial learning rate of 0.001. A `ReduceLROnPlateau` learning rate scheduler was employed, monitoring the validation loss and reducing the learning rate by a factor of 0.1 if no improvement was observed for 5 consecutive epochs.
* **Early Stopping:** Training for each fold incorporated an early stopping mechanism with a patience of 10 epochs. If the validation loss did not improve for this duration, training for that fold was halted, and the model weights corresponding to the best validation loss were retained.

Final predictions were generated by averaging the raw logits from the best models of all 5 folds. These averaged logits were then passed through a sigmoid function and thresholded at 0.5 to obtain binary class predictions (0 for "Cultivated 1st", 1 for "Cultivated 2nd"). Model performance was rigorously evaluated on the real samples using standard metrics including accuracy, precision, recall, and F1-score, and visualized through confusion matrices.

#### Grad-CAM for Interpretability

Grad-CAM visualizations were generated to provide insights into the regions of the ECT feature space most influential for the model's binary classification decisions. Heatmaps were computed by targeting the output of the final convolutional layer (`cam_model.features[8]`) of the best model from Fold 0. Average Grad-CAM heatmaps were calculated for each collection by summing heatmaps from 5 randomly selected real samples per class, normalizing them, and overlaying them onto representative ECT images.